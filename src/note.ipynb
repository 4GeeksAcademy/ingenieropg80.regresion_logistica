{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb5841ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv\"\n",
    "total_data = pd.read_csv(url, sep=\";\")  \n",
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d98424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables numéricas: ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "Variables no numéricas: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']\n"
     ]
    }
   ],
   "source": [
    "# Variables numéricas\n",
    "numericas = total_data.select_dtypes(include=['number']).columns.tolist()\n",
    "print(\"Variables numéricas:\", numericas)\n",
    "\n",
    "# Variables no numéricas (categóricas, texto, etc.)\n",
    "no_numericas = total_data.select_dtypes(exclude=['number']).columns.tolist()\n",
    "print(\"Variables no numéricas:\", no_numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95dd53fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET CON OUTLAIERS\n",
    "total_data.drop(['contact','day_of_week','month','duration','nr.employed','previous','pdays'], axis = 1, inplace = True)\n",
    "total_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f28f93f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'duration'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Reemplaza outliers con los valores limites para cada variable numerica\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m numericas:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     Q1 = \u001b[43mtotal_data_no_outliers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m]\u001b[49m.quantile(\u001b[32m0.25\u001b[39m)\n\u001b[32m      9\u001b[39m     Q3 = total_data_no_outliers[var].quantile(\u001b[32m0.75\u001b[39m)\n\u001b[32m     10\u001b[39m     IQR = Q3 - Q1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'duration'"
     ]
    }
   ],
   "source": [
    "# DATASET SIN OUTLAIERS \n",
    "\n",
    "# Crea una copia del dataset original\n",
    "total_data_no_outliers = total_data.copy()\n",
    "\n",
    "# Reemplaza outliers con los valores limites para cada variable numerica\n",
    "for var in numericas:\n",
    "    Q1 = total_data_no_outliers[var].quantile(0.25)\n",
    "    Q3 = total_data_no_outliers[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Reemplaza valores fuera de los limites\n",
    "    total_data_no_outliers[var] = total_data_no_outliers[var].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "print(\"Shape original:\", total_data.shape)\n",
    "print(\"Shape sin outliers:\", total_data_no_outliers.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689606c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'contact'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'contact'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m total_data_factorized = total_data.copy()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m no_numericas:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     total_data_factorized[col], _ = pd.factorize(\u001b[43mtotal_data_factorized\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m      7\u001b[39m total_data_factorized.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'contact'"
     ]
    }
   ],
   "source": [
    "# DATASET CON OUTLAIERS FACTORIZADO\n",
    "total_data_factorized = total_data.copy()\n",
    "\n",
    "for col in no_numericas:\n",
    "    total_data_factorized[col], _ = pd.factorize(total_data_factorized[col])\n",
    "\n",
    "total_data_factorized.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET SIN OUTLAIERS FACTORIZADO\n",
    "total_data_no_outliers_factorized = total_data_no_outliers.copy()\n",
    "\n",
    "# Factorizo solo las columnas categoricas indicadas en no_numericas\n",
    "for col in no_numericas:\n",
    "    total_data_no_outliers_factorized[col], _ = pd.factorize(total_data_no_outliers_factorized[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET TRAIN/TEST CON OUTLAIERS\n",
    "X = total_data.drop(columns=['y'])\n",
    "y = total_data['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36856f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET TRAIN/TEST SIN OUTLAIERS\n",
    "X = total_data_no_outliers.drop(columns=['y'])\n",
    "y = total_data_no_outliers['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecda410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET TRAIN/TEST FACTORIZADO CON OUTLAIERS\n",
    "X = total_data_factorized.drop(columns=['y'])\n",
    "y = total_data_factorized['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f98ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET TRAIN/TEST FACTORIZADO SIN OUTLAIERS\n",
    "X = total_data_no_outliers_factorized.drop(columns=['y'])\n",
    "y = total_data_no_outliers_factorized['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CON OUTLAIERS ESTANDARIZADO \n",
    "\n",
    "total_data_standard = total_data.copy()\n",
    "\n",
    "# columnas numericas excepto la target 'y'\n",
    "cols_to_scale = total_data_standard.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "\n",
    "# Inicializar scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar scaler solo a las columnas numéricas\n",
    "total_data_standard[cols_to_scale] = scaler.fit_transform(total_data_standard[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET SIN OUTLAIERS ESTANDARIZADO \n",
    "\n",
    "# Crear copia\n",
    "total_data_no_outliers_standard = total_data_no_outliers.copy()\n",
    "\n",
    "# Seleccionar columnas numéricas excepto la variable objetivo 'y'\n",
    "cols_to_scale = total_data_no_outliers_standard.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar scaler solo a las columnas numéricas\n",
    "total_data_no_outliers_standard[cols_to_scale] = scaler.fit_transform(total_data_no_outliers_standard[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b301b82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_data_factorized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# DATASET CON OUTLAIERS FACTORIZADO ESTANDARIZADO\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m total_data_factorized_standard = \u001b[43mtotal_data_factorized\u001b[49m.copy()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Selecciono columnas numericas excepto la variable objetivo 'y'\u001b[39;00m\n\u001b[32m      6\u001b[39m cols_to_scale = total_data_factorized_standard.drop(columns=[\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m]).select_dtypes(include=[\u001b[33m'\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m'\u001b[39m]).columns\n",
      "\u001b[31mNameError\u001b[39m: name 'total_data_factorized' is not defined"
     ]
    }
   ],
   "source": [
    "# DATASET CON OUTLAIERS FACTORIZADO ESTANDARIZADO\n",
    "\n",
    "total_data_factorized_standard = total_data_factorized.copy()\n",
    "\n",
    "# Selecciono columnas numericas excepto la variable objetivo 'y'\n",
    "cols_to_scale = total_data_factorized_standard.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar scaler solo a las columnas numericas\n",
    "total_data_factorized_standard[cols_to_scale] = scaler.fit_transform(total_data_factorized_standard[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50897abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET SIN OUTLAIERS FACTORIZADO ESTANDARIZADO\n",
    "total_data_no_outliers_factorized_standard = total_data_no_outliers_factorized.copy()\n",
    "\n",
    "# Selecciono columnas numericas excepto la variable objetivo 'y'\n",
    "cols_to_scale = total_data_no_outliers_factorized_standard.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "scaler = StandardScaler()\n",
    "# Aplicar scaler solo a las columnas numéricas\n",
    "total_data_no_outliers_factorized_standard[cols_to_scale] = scaler.fit_transform(total_data_no_outliers_factorized_standard[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CON OUTLAIERS MIN/MAX \n",
    "total_data_minmax = total_data.copy()\n",
    "cols_to_scale = total_data_minmax.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "scaler = MinMaxScaler()\n",
    "total_data_minmax[cols_to_scale] = scaler.fit_transform(total_data_minmax[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET SIN OUTLAIERS MIN/MAX \n",
    "total_data_no_outliers_minmax = total_data_no_outliers.copy()\n",
    "cols_to_scale = total_data_no_outliers_minmax.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "scaler = MinMaxScaler()\n",
    "total_data_no_outliers_minmax[cols_to_scale] = scaler.fit_transform(total_data_no_outliers_minmax[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ffa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CON OUTLAIERS FACTORIZADO MIN/MAX\n",
    "total_data_factorized_minmax = total_data_factorized.copy()\n",
    "cols_to_scale = total_data_factorized_minmax.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "scaler = MinMaxScaler()\n",
    "total_data_factorized_minmax[cols_to_scale] = scaler.fit_transform(total_data_factorized_minmax[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e5d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET SIN OUTLAIERS FACTORIZADO MIN/MAX\n",
    "total_data_no_outliers_factorized_minmax = total_data_no_outliers_factorized.copy()\n",
    "cols_to_scale = total_data_no_outliers_factorized_minmax.drop(columns=['y']).select_dtypes(include=['number']).columns\n",
    "scaler = MinMaxScaler()\n",
    "total_data_no_outliers_factorized_minmax[cols_to_scale] = scaler.fit_transform(total_data_no_outliers_factorized_minmax[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 14)\n",
      "(41188, 14)\n",
      "(41188, 14)\n",
      "(41188, 14)\n",
      "(41188, 14)\n",
      "(41188, 14)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_data_factorized_standard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(total_data_standard.shape)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(total_data_no_outliers_standard.shape)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtotal_data_factorized_standard\u001b[49m.shape)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(total_data_no_outliers_factorized_standard.shape)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(total_data_minmax.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'total_data_factorized_standard' is not defined"
     ]
    }
   ],
   "source": [
    "#Verfico el tamaño\n",
    "print(total_data.shape) # dataset con outlaiers\n",
    "print(total_data_no_outliers.shape) # dataset sin outlaiers\n",
    "print(total_data_factorized.shape) # dataset con outlaiers factorizado \n",
    "print(total_data_no_outliers_factorized.shape) # dataset sin outlaiers factorizado \n",
    "#train / test total_data # dataset con outlaiers\n",
    "#train / test total_data_no_outliers # dataset sin outlaiers\n",
    "#train / test total_data_factorized # dataset con outlaiers factorizado \n",
    "#train / test total_data_no_outliers_factorized # dataset sin outlaiers factorizado \n",
    "print(total_data_standard.shape)\n",
    "print(total_data_no_outliers_standard.shape)\n",
    "print(total_data_factorized_standard.shape)\n",
    "print(total_data_no_outliers_factorized_standard.shape)\n",
    "print(total_data_minmax.shape)\n",
    "print(total_data_no_outliers_minmax.shape)\n",
    "print(total_data_factorized_minmax.shape)\n",
    "print(total_data_no_outliers_factorized_minmax.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a1c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test total_data_factorized y total_data_no_outliers_factorized\n",
    "# Para total_data_factorized\n",
    "X_factorized = total_data_factorized.drop(columns=['y'])\n",
    "y_factorized = total_data_factorized['y']\n",
    "\n",
    "X_train_factorized, X_test_factorized, y_train_factorized, y_test_factorized = train_test_split(\n",
    "    X_factorized, y_factorized, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Para total_data_no_outliers_factorized\n",
    "X_no_outliers = total_data_no_outliers_factorized.drop(columns=['y'])\n",
    "y_no_outliers = total_data_no_outliers_factorized['y']\n",
    "\n",
    "X_train_no_outliers, X_test_no_outliers, y_train_no_outliers, y_test_no_outliers = train_test_split(\n",
    "    X_no_outliers, y_no_outliers, test_size=0.2, random_state=42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
